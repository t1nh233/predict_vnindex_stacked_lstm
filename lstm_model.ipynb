{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPuQx/ExQkPlcC/MDj3VYdd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/t1nh233/predict_vnindex_stacked_lstm/blob/main/lstm_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "T5NTTcF27HpV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf0f4971-ff6b-4cb7-8b2a-cbe070ef9200"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas_ta in /usr/local/lib/python3.12/dist-packages (0.4.71b0)\n",
            "Requirement already satisfied: numba==0.61.2 in /usr/local/lib/python3.12/dist-packages (from pandas_ta) (0.61.2)\n",
            "Requirement already satisfied: numpy>=2.2.6 in /usr/local/lib/python3.12/dist-packages (from pandas_ta) (2.2.6)\n",
            "Requirement already satisfied: pandas>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from pandas_ta) (2.3.3)\n",
            "Requirement already satisfied: tqdm>=4.67.1 in /usr/local/lib/python3.12/dist-packages (from pandas_ta) (4.67.1)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba==0.61.2->pandas_ta) (0.44.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.3.2->pandas_ta) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.3.2->pandas_ta) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.3.2->pandas_ta) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.3.2->pandas_ta) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas_ta\n",
        "import pandas as pd\n",
        "import pandas_ta as ta\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Dữ liệu và tiền xử lý dữ liệu**\n",
        "### **1.1. Thu thập và làm sạch dữ liệu**\n",
        "Dữ liệu lịch sử của chỉ số VN-Index được thu thập từ nền tảng [Investing.com](https://www.investing.com/indices/vn-historical-data) trong giai đoạn từ **12/09/2010 đến 12/09/2025**. Tập dữ liệu thô bao gồm các trường thông tin cơ bản: **Giá mở cửa (Open)**, **Giá cao nhất (High)**, **Giá thấp nhất (Low)**, **Giá đóng cửa (Price/Close)**, **Khối lượng giao dịch (Vol)** và **Phần trăm thay đổi (Change)**.\n",
        "\n",
        "Để đảm bảo được tính nhất quán và phú hợp cho mô hình huấn luyện, quá trình làm sạch dữ liệu được thực hiện qua các bước sau:\n",
        "1. **Định dạng thời gian**: Chuyển đổi cột **Date** sang định dạng `datetime` chuẩn và thiết lập làm chỉ số (Index) cho chuỗi thời gian.\n",
        "2. **Chuẩn hóa định dạng số**: Xử lý dấu phân cách thập phân/ hàng nghìn (loại bỏ đấu phẩy gây nhiễu trong dữ liệu gốc).\n",
        "3. **Chuyển đổi đơn vị đo lường**: Quy đổi các giá trị Khối lượng (Volume) và Phần trăm thay đổi (Change) từ dạng ký tự viết tắt về dạng số thực nguyên bản.\n",
        "4. **Ép kiểu dữ liệu**: Toàn bộ các đặc trưng số được được chuyển đổi thống nhất về kiểu dữ liệu `float64` để phục vụ việc tính toán sau này.\n"
      ],
      "metadata": {
        "id": "fgdkpsBZWuH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Doc du lieu\n",
        "url = \"https://raw.githubusercontent.com/t1nh233/predict_vnindex_stacked_lstm/refs/heads/main/vn_index_historical_data_9_12.csv\"\n",
        "vnindex = pd.read_csv(url)\n",
        "vnindex.head()\n",
        "\n",
        "\n",
        "## Xu ly du lieu thoi gian va dua Date thanh index\n",
        "vnindex['Date'] = pd.to_datetime(vnindex['Date'], format='%m/%d/%Y')\n",
        "vnindex = vnindex.sort_values(by='Date')\n",
        "vnindex.set_index('Date', inplace=True)\n",
        "\n",
        "\n",
        "## Chuyen doi ve dung dinh dang va dung don vi\n",
        "columns_convert_to_float = [\"Price\", \"Open\", \"High\", \"Low\"]\n",
        "for column in columns_convert_to_float:\n",
        "    vnindex[column] = vnindex[column].str.replace(\",\", \"\").astype(float)\n",
        "\n",
        "\n",
        "### Ham ho tro chuyen doi Volume\n",
        "def convert_volume(vol_str):\n",
        "    multiplier_dict = {\"K\": 1000, \"M\": 1000000, \"B\": 1000000000}\n",
        "\n",
        "    if not isinstance(vol_str, str):\n",
        "        return vol_str\n",
        "\n",
        "    vol_str = vol_str.upper().strip()\n",
        "    last_char = vol_str[-1]\n",
        "\n",
        "    if last_char in multiplier_dict.keys():\n",
        "        multiplier_val = multiplier_dict[last_char]\n",
        "        number_part = vol_str[:-1]\n",
        "    else:\n",
        "        multiplier_val = 1\n",
        "        number_part = vol_str\n",
        "\n",
        "    try:\n",
        "        number = float(number_part.replace(',', ''))\n",
        "    except ValueError:\n",
        "        return np.nan\n",
        "\n",
        "    return number * multiplier_val\n",
        "\n",
        "\n",
        "### Ham ho tro chuyen doi Change\n",
        "def convert_change(change_str):\n",
        "    if not isinstance(change_str, str):\n",
        "        return change_str\n",
        "\n",
        "    if change_str.endswith('%'):\n",
        "        number_part = change_str[:-1]\n",
        "    else:\n",
        "        number_part = change_str\n",
        "\n",
        "    try:\n",
        "        number = float(number_part.replace(',', ''))\n",
        "    except ValueError:\n",
        "        return np.nan\n",
        "\n",
        "    return number / 100.0\n",
        "\n",
        "\n",
        "## Bien doi Volume va Change\n",
        "vnindex['Vol.'] = vnindex['Vol.'].apply(convert_volume)\n",
        "vnindex['Change %'] = vnindex['Change %'].apply(convert_change)\n",
        "\n",
        "\n",
        "## Doi ten cot ve dang chuan hon\n",
        "vnindex.rename(columns={'Price': 'Close', 'Vol.': 'Volume', 'Change %': 'Change'}, inplace=True)\n",
        "\n",
        "\n",
        "## Them cot label vao cuoi cua moi ngay\n",
        "vnindex['label'] = vnindex['Close'].shift(-1)\n",
        "\n",
        "##Lay log cua Volume\n",
        "vnindex['Volume'] = np.log1p(vnindex['Volume'])\n",
        "\n",
        "# ## Kiem tra lai du lieu da xu ly\n",
        "print(vnindex.info())\n",
        "print(vnindex.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAnYYPxD786O",
        "outputId": "fe28886b-644f-4c45-8cf6-67fcca23e67d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 3743 entries, 2010-12-09 to 2025-12-09\n",
            "Data columns (total 7 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   Close   3743 non-null   float64\n",
            " 1   Open    3743 non-null   float64\n",
            " 2   High    3743 non-null   float64\n",
            " 3   Low     3743 non-null   float64\n",
            " 4   Volume  3743 non-null   float64\n",
            " 5   Change  3743 non-null   float64\n",
            " 6   label   3742 non-null   float64\n",
            "dtypes: float64(7)\n",
            "memory usage: 233.9 KB\n",
            "None\n",
            "             Close    Open    High     Low     Volume  Change   label\n",
            "Date                                                                 \n",
            "2010-12-09  460.45  450.59  460.79  450.16  11.011572  0.0168  473.06\n",
            "2010-12-10  473.06  464.81  473.06  462.39  11.452230  0.0274  490.22\n",
            "2010-12-13  490.22  485.82  490.30  485.73  11.314243  0.0363  489.65\n",
            "2010-12-14  489.65  493.72  496.42  480.64  11.812667 -0.0012  493.47\n",
            "2010-12-15  493.47  492.80  497.09  491.51  11.468775  0.0078  480.21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.2. Trích xuất đặc trưng kỹ thuật (Feature Extraction)**\n",
        "Mặc dù dữ liệu giá gốc (OHLCV) cung cấp thông tin nền tảng, theo các nghiên cứu nhận định rằng việc chỉ sử dụng giá đóng của thô (Raw Close Price) là chưa đủ để mô hình nắm bắt được các mẫu hình phức tạp của thị trường. Dựa trên các các công trinh nghiên cứu liên quan đến dự báo chuỗi thời gian tài chính, nhóm tiến hành trích xuất thêm các chỉ bảo phân tích kỹ thuật làm đầu vào bổ sung. Các đặc trưng này được phân loại thành 3 nhóm chính:\n",
        "#### **1.2.1. Nhóm chỉ báo Xu hướng (Trend Indicators)**\n",
        "Nhóm chỉ báo này giúp khử nhiễu biến động giá ngẫu nhiên và xác định hướng di chuyển chính của thị trường:\n",
        "- **SMA (Simple Moving Average - Đường trung bình động đơn giản)**: Được tính bằng trung bình cộng giá đóng của trong **chu kỳ 20 ngày (tương đương 1 tháng giao dịch)**. Việc lựa chọn `SMA(20)` giúp làm mượt dữ liệu và xác định được xu hướng ngắn hạn.\n",
        "- **EMA (Exponential Moving Average - Đường trung bình động lũy thừa)**: Khác với SMA, EMA đặt trọng số lớn hơn vào các dữ liệu giá gần nhất nhằm giảm độ trễ (lag) và phản ứng nhạy hơn với các biến động hiện tại. Nhóm sử dụng EMA với **chu kỳ 50 ngày** để nắm bắt xu hướng trung hạn và đóng vai trò như ngưỡng hỗ trợ/ kháng cự động."
      ],
      "metadata": {
        "id": "CKgHsD22iRvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SMA(20)\n",
        "vnindex['SMA'] = ta.sma(vnindex['Close'], length=20)\n",
        "\n",
        "# EMA(50)\n",
        "vnindex['EMA'] = ta.ema(vnindex['Close'], length=50)"
      ],
      "metadata": {
        "id": "DjAp4SsaOU6V"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.2. Nhóm chỉ báo Động lượng và Biến động (Momentum & Volatility Indicators)**\n",
        "Các chỉ báo này cung cấp thông tin về sức mạnh của xu hướng và độ rủi ro của thị trường:\n",
        "- **RSI (Relative Strength Index - Chỉ số sức mạnh tương đối)**: Đo lường tốc độ và mức độ thay đổi giá để xác định các vùng quá mua hoặc quá bán. Tham số chu kỳ được thiết lập là **14 ngày** theo khuyến nghị chuẩn của tác giả **J. Welles Wilder**.\n",
        "- **MACD (Moving Average Convergence Divergence)**: Phân tích mối quan hệ giữa hai đường trung bình động (EMA) để phát hiện sự thay đổi trong sức mạnh, hướng và động lượng của thị trường. Bộ tham số tiêu chuẩn **(12, 26, 9)** được áp dụng dựa trên đề xuất của **Gerald Appel**.\n",
        "- **BB (Bollinger Bands - Dải Bollinger)**: Đo lường độ biến động của thị trường. Chỉ báo được cấu thành từ một đường trung bình động (SMA 20) và hai dải biên trên/dưới các nhau 2 độ lệch chuẩn (std = 2.0). Đây là thiết lập tối ưu để bao quát khoảng 95% biến động giá thông thường."
      ],
      "metadata": {
        "id": "sGMDiiMyOZyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RSI (14)\n",
        "vnindex['RSI'] = ta.rsi(vnindex['Close'], length=14)\n",
        "\n",
        "\n",
        "# MACD(12, 26, 9)\n",
        "vnindex['MACD'] = ta.macd(vnindex['Close'])['MACD_12_26_9']\n",
        "vnindex['MACD_Signal'] = ta.macd(vnindex['Close'])['MACDs_12_26_9']\n",
        "vnindex['MACD_Hist'] = ta.macd(vnindex['Close'])['MACDh_12_26_9']\n",
        "\n",
        "\n",
        "# BB(20, 2.0)\n",
        "bb_values = ta.bbands(vnindex['Close'], length=20, std=2.0)\n",
        "vnindex['BB_Width'] = ta.bbands(vnindex['Close'], length=20, std=2.0)['BBB_20_2.0_2.0']\n",
        "vnindex['BB_Percentage'] = ta.bbands(vnindex['Close'], length=20, std=2.0)['BBP_20_2.0_2.0']"
      ],
      "metadata": {
        "id": "62CO5sG3-udk"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.3. Cơ sở lựa chọn đặc trưng đầu vào**\n",
        "Sau khi tính toán các đặc trưng kỹ thuật xong, việc lựa chọn những đặc trưng nào để huấn luyện cũng là một bước quan trọng. Cụ thể các nhóm đặc trưng được lựa chọn vì những lý do sau:\n",
        "1. **Nhóm Dữ liệu gốc (Raw Data)**\n",
        "   - **Close (Giá đóng cửa)**: Là đặc trưng không thể thiếu, đây là nền tảng để tính toán mọi chỉ báo khác.\n",
        "   - **Volume (Khối lượng)**: Volume là đậc trưng xác nhận sức mạnh của xu hướng. Việc đưa Volume vào giúp mô hình phân biệt được đâu là tính hiệu thật, đâu là tín hiệu giả (giá tăng nhưng volume thấp → tín hiệu giả).\n",
        "2. **Nhóm Xu hướng (Trend)**\n",
        "   - Dữ liệu giá theo ngày thường bị nhiễu. **SMA và EMA** giúp làm mượt dữ liệu, giúp mô hình nhận diện được hướng đi chủ đạo thay vì bị mắc kẹt ở các biến động nhỏ lẻ trong ngày.\n",
        "3. **Nhóm Động lượng (Momentum)**\n",
        "   - **RSI**: Giúp mô hình phát hiện các điểm đảo chiều tiềm năng thông qua vùng Quá mua/Quá bán. Quan trọng hơn, RSI giúp phát hiện tín hiệu phân kỳ.\n",
        "   - **MACD_Hist**: Thay vì dùng đường MACD, việc sử dụng Histogram giúp mô hình đo lường gia tốc của xu hướng. Histogram đổi màu hoặc tiến về 0 là dấu hiệu cho thấy xu hướng hiện tại đang yếu đi.\n",
        "4. **Nhóm Biến động (Volatility)**\n",
        "   - **BB_Width**: Đại diện cho mức độ biến động của thị trường. Khi **BB_Width** co lại báo hiệu thị trường sắp có biến động bùng nổ. Đặc trưng này giúp mô hình chuẩn bị cho các đợt biến động mạnh sắp xảy ra.\n",
        "   - **BB_Percentage**: Là đặc trưng đã được chuẩn hóa, cho biết vị trí tương đối của giá so với hai dải băng, cho biết vị trí tương đối của giá so với hai dải băng. Giá trị này có tính hữu ích cao vì nó đã được chuẩn hóa vị trí giá về một phạm vi tương đối, giúp mô hình dễ học hơn so với giá trị tuyệt đối.\n",
        "\n"
      ],
      "metadata": {
        "id": "XE8M2dh2wwd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Xoa cac dong NaN(co it nhat 1 gia tri Nan trong hang = xoa)\n",
        "vnindex_clean = vnindex.dropna()\n",
        "\n",
        "\n",
        "## Chon va sap xep lai cac features\n",
        "feature_columns = ['Close', 'Volume', 'RSI', 'SMA', 'EMA', 'MACD_Hist', 'BB_Width', 'BB_Percentage']\n",
        "target_column = 'label'\n",
        "\n",
        "all_data_cleaned = vnindex_clean.columns.tolist()\n",
        "train_feature = feature_columns + [target_column]\n",
        "train_feature_data = vnindex_clean[train_feature].copy()\n",
        "train_feature_cols = train_feature_data.columns.tolist()\n",
        "target_index = train_feature_cols.index(target_column)"
      ],
      "metadata": {
        "id": "cP-0Owg72qoH"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**1.4. Chia tập dữ liệu (Train/Validation/Test Split)**\n",
        "Để đánh giá hiệu quả của mô hình và ngăn chặn hiện tượng quá khớp (Overfitting), tập dữ liệu sau khi tiền xử lý được chia thành 3 phần độc lập: **Tập huấn luyện (Training set)**, **Tập kiểm định (Validation set)** và **Tập kiểm tra (Test set)** theo **tỷ lệ 70% - 20% - 10%**.\n",
        "\n",
        "Với tổng thời gian thu tập 15 năm (2010 - 2025), tỷ lệ **10%** cho **tập kiểm tra** tương đương khoảng 1.5 năm dữ liệu giao dịch. Đây là khoảng thời gian đủ lớn để bao quát các biến động thị trường, đảm bảo kết quả đánh giá mang tính khách quan và tin cậy.\n",
        "\n",
        "**Lưu ý**: Khác với các bài toán hồi quy thông thường, dữ liệu chứng khoán có tính phụ thuộc thời gian, do đó phương pháp phân chia ngẫu nhiên (Random Shuffle) không được áp dụng để tránh hiện tượng rò rỉ dữ liệu tương lai."
      ],
      "metadata": {
        "id": "WjEboFpEXRDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Chia tap du lieu thanh Train, Valid va Test\n",
        "\n",
        "total_samples = len(train_feature_data)\n",
        "train_set_size = int(total_samples * 0.7)\n",
        "valid_set_size = int(total_samples * 0.2)\n",
        "test_set_size = total_samples - train_set_size - valid_set_size\n",
        "\n",
        "train_size = int(len(train_feature_data) * 0.7)\n",
        "val_size = int(len(train_feature_data) * 0.15)\n",
        "test_size = len(train_feature_data) - train_set_size - valid_set_size\n",
        "\n",
        "train_data = train_feature_data[:train_set_size]\n",
        "val_data = train_feature_data[train_set_size : train_set_size + valid_set_size]\n",
        "test_data = train_feature_data[train_set_size + valid_set_size:]"
      ],
      "metadata": {
        "id": "d29vMkhDuk4I"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.5. Chuẩn hóa dữ liệu (Normalization)**\n",
        "Trong mô hình mạng neural hồi quy (RNN) nói chung và LSTM nói riêng, bước chuẩn hóa dữ liệu là bước bắt buộc trong phần tiền xử lý dữ liệu vì hai lý do chính:\n",
        "1. **Độ hội tụ**: Dữ liệu tài chính thường có sự chếnh lệch lớn về độ lớn (ví dụ: giá trị khối lượng giao dịch có thể lên tới vào trăm ngàn, trong khi tỷ lệ thay đổi giá chỉ là số thập phân nhỏ). Nếu không chuẩn hóa, Gradient Descent sẽ mất rất nhiều thời gian để hội tụ hoặc bị kẹt ở điểm cực tiểu địa phương.\n",
        "2. **Đặc tính của hàm kích hoạt**: Vì các cổng trong LSTM sử dụng hàm kích hoạt **Sigmoid và Tanh**. Nếu dữ liệu đầu vào quá lớn hoặc quá nhỏ, dẫn đến các đạo hàm gằn bằng 0 hay còn gọi là hiện tượng biến mất đạo hàm (Vanishing Gradient).\n",
        "\n",
        "**Phương pháp: Min - Max Scaling**\n",
        "Phương pháp này chuyển đổi dữ liệu về một phạm vi cố định là `[0, 1]`. Công thức tổng quát cho một giá trị x bất kỳ:\n",
        "\n",
        "$$x' = \\frac{x - min(X)}{max(X) - min(X)}$$\n",
        "\n",
        ">với `x` là giá trị gốc và `x'` là giá trị sau khi được chuẩn hóa\n",
        "\n",
        "**Lưu ý**: Chỉ `fit` trên tập **Train**. Sau đó dùng thông số này để `transform` trên tập **Valid và Test** để tránh việc mô hình nhìn thấy trước được tương lai (Data Leakage)."
      ],
      "metadata": {
        "id": "Ff95jmji24kh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Khoi tao scaler (chi fit tren tap train)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaler.fit(train_data)\n",
        "\n",
        "## Transform tren ca 3 tap\n",
        "train_scaled = scaler.transform(train_data)\n",
        "val_scaled = scaler.transform(val_data)\n",
        "test_scaled = scaler.transform(test_data)"
      ],
      "metadata": {
        "id": "Z52L4cmN8drb"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Xây dựng mô hình**\n",
        "### **2.1. Tạo cửa sổ trượt (Sliding Window)**"
      ],
      "metadata": {
        "id": "-zy6toZW9gSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_windows(data, window_size, target_col_index):\n",
        "    X, y = [], []\n",
        "\n",
        "    for i in range(len(data) - window_size):\n",
        "        X.append(data[i:i + window_size, :-1])\n",
        "        y.append(data[i + window_size, target_col_index])\n",
        "\n",
        "    X_tensor = torch.tensor(np.array(X), dtype=torch.float32)\n",
        "    y_tensor = torch.tensor(np.array(y), dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "    return X_tensor, y_tensor\n",
        "\n",
        "WINDOW_SIZE = 30\n",
        "TARGET_INDEX = target_index\n",
        "\n",
        "X_train, y_train = create_windows(train_scaled, WINDOW_SIZE, TARGET_INDEX)\n",
        "X_val, y_val = create_windows(val_scaled, WINDOW_SIZE, TARGET_INDEX)\n",
        "X_test, y_test = create_windows(test_scaled, WINDOW_SIZE, TARGET_INDEX)"
      ],
      "metadata": {
        "id": "5VTJKMkr8Laj"
      },
      "execution_count": 53,
      "outputs": []
    }
  ]
}