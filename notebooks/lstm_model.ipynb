{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/t1nh233/predict_vnindex_stacked_lstm/blob/main/notebooks/lstm_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "T5NTTcF27HpV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc4796a2-0551-447d-bfcf-d1461510b266"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.45)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading optuna-4.6.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.10.1 optuna-4.6.0\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import optuna\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Load du lieu\n",
        "url = \"https://raw.githubusercontent.com/t1nh233/predict_vnindex_stacked_lstm/refs/heads/main/data/raw/vn_index_historical_data_9_12.csv\"\n",
        "vnindex = load_and_process_data(url)\n",
        "\n",
        "## Xu ly cac dac trung moi\n",
        "vnindex_feature = feature_extraction(vnindex)\n",
        "\n",
        "## Cac dac trung su dung de huan luyen\n",
        "FEATURE_COLUMNS = ['Close', 'Volume', 'RSI', 'SMA', 'EMA', 'MACD_Hist', 'BB_Width', 'BB_Percentage']\n",
        "TARGET_COLUMN = 'Label'\n",
        "\n",
        "## Trich xuat du lieu theo cac dac trung huan luyen\n",
        "feature_data = vnindex_feature[FEATURE_COLUMNS + [TARGET_COLUMN]].copy()\n",
        "TARGET_INDEX = feature_data.columns.get_loc(TARGET_COLUMN)\n",
        "\n",
        "## Chia tap du lieu train, valid, set theo ti le 70:20:10\n",
        "train_df, val_df, test_df = split_data(train_df, 0.7, 0.2)\n",
        "\n",
        "## Scale data ve (0, 1)\n",
        "scaler, train_scaled_df, val_scaled_df, test_scaled_df = scale_data(train_df, val_df, test_df, FEATURE_COLUMNS)\n",
        "\n",
        "## Tao input (sliding window) cho LSTM\n",
        "WINDOW_SIZE = 30\n",
        "X_train, y_train = create_sliding_window(train_scaled_df, WINDOW_SIZE, TARGET_INDEX)\n",
        "X_val, y_val = create_sliding_window(val_scaled_df, WINDOW_SIZE, TARGET_INDEX)\n",
        "X_test, y_test = create_sliding_window(test_scaled_df, WINDOW_SIZE, TARGET_INDEX)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cude.is_available() else \"cpu\")\n",
        "\n",
        "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "val_dataset = torch.utils.data.TensorDataset(X_val, y_val)\n",
        "\n",
        "## De luu tham so sau khi dieu chinh va model sau khi huan luyen\n",
        "save_dir = os.path.join('..', 'models')\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "## Dieu chinh tham so cua mo hinh (chon ra bo tham so tot nhat)\n",
        "\n",
        "def hyper_tuning(trial):\n",
        "  ## Sieu tham so cho model\n",
        "  hidden_size = trial.suggest_categorical(\"hidden_size\", [32, 64, 128, 256])\n",
        "  num_layers = trial.suggest_int(\"num_layers\", 1, 3)\n",
        "  dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n",
        "\n",
        "  ## Sieu tham so cho optimizer\n",
        "  learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
        "  weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
        "\n",
        "  batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "  val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  ## Khoi tao model\n",
        "  model = LSTMModel(\n",
        "      input_size = X_train.shape[2],\n",
        "      hidden_size = hidden_size,\n",
        "      num_layers = num_layers,\n",
        "      dropout_rate = dropout_rate\n",
        "  ).to(device)\n",
        "\n",
        "  loss_func = nn.HuberLoss(delta=1.0)\n",
        "  optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "  ## Training voi epoch 10 tren train de test\n",
        "  for epoch in range(10):\n",
        "    model.train()\n",
        "    for X_batch, y_batch in train_loader:\n",
        "      X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      y_pred = model(X_batch)\n",
        "      loss = loss_func(y_batch, y_pred)\n",
        "      loss.backward()\n",
        "\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "      optimizer.step()\n",
        "\n",
        "  ## Validate\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "      for X_batch_v, y_batch_v in val_loader:\n",
        "        X_batch_v, y_batch_v = X_batch_v.to(device), y_batch_v.to(device)\n",
        "\n",
        "        y_pred_v = model(X_batch_v)\n",
        "        loss = loss_func(y_batch_v, y_pred_v)\n",
        "        val_loss += loss.item()\n",
        "\n",
        "    ## In ra ket qua khi chay tren bo tham so nay\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    trial.report(avg_val_loss, epoch)\n",
        "\n",
        "    if trial.should_prune():\n",
        "      raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "  return avg_val_loss\n",
        "\n",
        "## Bat dau chay\n",
        "print(\"Start tuning\")\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(hyper_tuning, n_trials=20)\n",
        "\n",
        "## Tra ve bo tham so toi uu nhat\n",
        "print(\"Best parameter: \", study.best_params)\n",
        "best_params = study.best_params\n",
        "\n",
        "## Luu best params vao file\n",
        "best_params_config = {\n",
        "    \"window_size\": WINDOW_SIZE,\n",
        "    \"feature_columns\": FEATURE_COLUMNS,\n",
        "    **best_params\n",
        "}\n",
        "\n",
        "params_path = os.path.join(save_dir, 'best_params.json')\n",
        "with open(params_path, 'w') as f:\n",
        "    json.dump(best_params_config, f, indent=4)"
      ],
      "metadata": {
        "id": "LsP6Z1OpIFH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Huan luyen mo hinh\n",
        "final_batch_size = best_params['batch_size']\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=final_batch_size, shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=final_batch_size, shuffle=False)\n",
        "\n",
        "model = LSTMModel(\n",
        "    input_size = X_train.shape[2],\n",
        "    hidden_size = best_params['hidden_size'],\n",
        "    num_layers = best_params['num_layers'],\n",
        "    dropout_rate = best_params['dropout_rate']\n",
        ").to(device)\n",
        "\n",
        "loss_func = nn.HuberLoss(delta=1.0)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=best_params['learning_rate'], weight_decay=best_params['weight_decay'])\n",
        "\n",
        "NUM_EPOCHS = 100\n",
        "best_val_loss = float('inf')\n",
        "history = {'train_loss': [], 'val_loss': []}\n",
        "\n",
        "print(\"Start training\")\n",
        "model_path = os.path.join(save_dir, 'best_vnindex_lstm.pth')\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  avg_train_loss = train_model(model, train_loader, loss_func, optimizer, device)\n",
        "  avg_val_loss = validate_model(model, val_loader, loss_func, device)\n",
        "\n",
        "  history['train_loss'].append(avg_train_loss)\n",
        "  history['val_loss'].append(avg_val_loss)\n",
        "\n",
        "  if avg_val_loss < best_val_loss:\n",
        "    best_val_loss = avg_val_loss\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "\n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    print(f'Epoch [{epoch + 1}/{NUM_EPOCHS}], Train Loss: {avg_train_loss:.5f}, Val Loss: {avg_val_loss:.5f}')\n",
        "\n",
        "## Ve bieu do train_loss va val_loss\n",
        "plt.plot(history['train_loss'], label='Train Loss')\n",
        "plt.plot(history['val_loss'], label='Val Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RzAv_b_kNw_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = os.path.join('..', 'models', 'best_vnindex_lstm.pth')\n",
        "\n",
        "# Load trong so da huan luyen vao model\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "model.to(device)\n",
        "\n",
        "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=final_batch_size, shuffle=False)\n",
        "\n",
        "## Du doan tren tap test\n",
        "preds, targets = predict_model(model, test_loader, device)\n",
        "\n",
        "## Inverse lai cac gia tri\n",
        "final_preds = inverse_transform_target(preds, scaler, TARGET_INDEX)\n",
        "final_targets = inverse_transform_target(targets, scaler, TARGET_INDEX)\n",
        "\n",
        "## Tinh metrics\n",
        "mae, rmse, r2_score = cal_metrics(final_targets, final_preds)\n",
        "\n",
        "print(f\"MAE: {mae:.2f} điểm\")\n",
        "print(f\"RMSE: {rmse:.2f} điểm\")\n",
        "print(f\"R2 Score: {r2:.4f}\")\n",
        "\n",
        "# Ve bieu do truc quan giua gia tri thuc te va gia tri du doan\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(final_targets, label='Thực tế (VN-Index)', color='blue')\n",
        "plt.plot(final_preds, label='Dự báo (LSTM)', color='red', alpha=0.7)\n",
        "plt.title('So sánh Giá trị thực tế và Giá trị mô hình dự báo trên Test set')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8UG4UtnXedIo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}